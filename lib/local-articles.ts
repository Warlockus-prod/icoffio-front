import type { Post, Category } from "./types";

// Локальные статьи для добавления на сайт
export const localArticles: Post[] = [
  {
    slug: "chto-nuzhno-znat-esli-vy-reshili-vnedrit-llm",
    title: "Что нужно знать, если вы решили внедрить LLM",
    excerpt: "Подробное руководство по внедрению больших языковых моделей в ваш продукт. Стратегии, тактики и реальный опыт от эксперта Яндекса.",
    date: new Date().toISOString(),
    publishedAt: new Date().toISOString(),
    image: "/images/ai-llm-implementation.jpg",
    imageAlt: "Схема внедрения LLM в продукт",
    category: { name: "AI", slug: "ai" },
    images: [
      "/images/ai-llm-implementation.jpg",
      "/images/ai-strategy-planning.jpg", 
      "/images/ai-development-process.jpg"
    ],
    contentHtml: `
<div class="prose prose-lg max-w-none">
  <img src="/images/ai-llm-implementation.jpg" alt="Внедрение LLM в продукт" class="w-full h-64 object-cover rounded-lg mb-8" />
  
  <p class="lead">Вокруг LLM очень много мистификации. Многие считают, что только особенные люди после специального образования могут освоить таинство работы с большими языковыми моделями. Это не так. В этой статье разберем, как эффективно внедрить LLM в ваш продукт.</p>

  <h2>Куда и зачем внедрять LLM?</h2>
  
  <p>ИИ успешно существовал и до появления LLM. Сферы, где классический ИИ приносит много пользы:</p>
  <ul>
    <li>Поиск и ранжирование результатов</li>
    <li>Рекомендательные системы в e-commerce</li>
    <li>Рекомендации контента в социальных сетях</li>
    <li>Таргетированная реклама</li>
  </ul>

  <p>Здесь работают классические модели: градиентный бустинг, коллаборативная фильтрация, факторизационные машины. LLM отличаются принципиально:</p>

  <h3>Ключевые отличия LLM</h3>
  
  <div class="bg-blue-50 p-6 rounded-lg mb-8">
    <h4>1. Взаимодействие через текст</h4>
    <p>LLM обучается через задачу предсказания следующего слова. Благодаря этому с моделью можно "поговорить" — ввести промпт и получить текстовый ответ.</p>
  </div>

  <div class="bg-green-50 p-6 rounded-lg mb-8">
    <h4>2. Обобщаемость</h4>
    <p>До LLM под каждую задачу нужно было создавать отдельную модель. LLM можно настроить текстом, объяснив что требуется.</p>
  </div>

  <img src="/images/ai-strategy-planning.jpg" alt="Планирование стратегии ИИ" class="w-full h-64 object-cover rounded-lg my-8" />

  <h2>Стратегия внедрения</h2>

  <p>Исследования показывают, что 80% всех ИИ проектов проваливаются. Чтобы этого избежать, нужна правильная стратегия:</p>

  <h3>1. Определение целей и задач</h3>
  <p>Четко сформулируйте, какие конкретные задачи должна решать LLM в вашем продукте. Избегайте размытых формулировок типа "улучшить пользовательский опыт".</p>

  <h3>2. Выбор подходящей модели</h3>
  <p>Решите, использовать ли готовую модель (OpenAI, Claude, Gemini) или обучать собственную. В большинстве случаев готовые решения предпочтительнее.</p>

  <h3>3. Планирование интеграции</h3>
  <p>Продумайте архитектуру системы, API endpoints, обработку ошибок и масштабирование нагрузки.</p>

  <h2>Тактика реализации</h2>

  <p>У вас есть всего 3 основных инструмента для улучшения работы LLM:</p>

  <h3>Промпт-инжиниринг</h3>
  <p>Искусство составления правильных запросов к модели. Это самый быстрый и дешевый способ получить нужный результат.</p>

  <div class="bg-yellow-50 p-6 rounded-lg mb-6">
    <h4>Принципы хорошего промпта:</h4>
    <ul>
      <li>Четкие инструкции с конкретными примерами</li>
      <li>Определение роли и контекста</li>
      <li>Структурированный формат ответа</li>
      <li>Ограничения и условия выполнения</li>
    </ul>
  </div>

  <h3>RAG (Retrieval-Augmented Generation)</h3>
  <p>Технология дополнения запроса релевантной информацией из внешних источников. Позволяет модели использовать актуальные данные, которых не было в обучающей выборке.</p>

  <img src="/images/ai-development-process.jpg" alt="Процесс разработки ИИ" class="w-full h-64 object-cover rounded-lg my-8" />

  <h3>Дообучение (Fine-tuning)</h3>
  <p>Самый дорогой метод. Рекомендуется только в 5% случаев, когда промптинг и RAG не дают нужного результата.</p>

  <h2>Контроль качества</h2>

  <p>LLM могут галлюцинировать — выдавать правдоподобную, но неточную информацию. Обязательные меры:</p>

  <ul>
    <li>Автоматическое тестирование на наборе эталонных случаев</li>
    <li>A/B тестирование разных версий промптов</li>
    <li>Мониторинг качества ответов в продакшене</li>
    <li>Feedback loops для постоянного улучшения</li>
  </ul>

  <h2>Практические советы</h2>

  <div class="bg-red-50 p-6 rounded-lg mb-6">
    <h3>❌ Чего НЕ стоит делать:</h3>
    <ul>
      <li>Начинать с дообучения модели</li>
      <li>Игнорировать вопросы безопасности</li>
      <li>Недооценивать важность качественных данных</li>
      <li>Забывать про пользовательский опыт</li>
    </ul>
  </div>

  <div class="bg-green-50 p-6 rounded-lg mb-6">
    <h3>✅ Что СТОИТ делать:</h3>
    <ul>
      <li>Начинать с простых задач</li>
      <li>Быстро итерироваться и тестировать</li>
      <li>Инвестировать в инфраструктуру мониторинга</li>
      <li>Обучать команду работе с LLM</li>
    </ul>
  </div>

  <h2>Заключение</h2>

  <p>Внедрение LLM — это не магия, а инженерная задача со своими принципами и лучшими практиками. Главное — начинать с малого, тщательно тестировать и постоянно улучшать систему на основе реальной обратной связи.</p>

  <p>LLM значительно удешевляют доступ к ИИ технологиям. Раньше нужно было создавать модели с нуля, теперь можно взять готовое решение и адаптировать под свои задачи.</p>

  <blockquote class="text-xl italic border-l-4 border-blue-500 pl-6 my-8">
    "В мире неопределенности LLM проектов ключ к успеху — быстрая итерация, тщательное тестирование и постоянное обучение."
  </blockquote>

  <p><em>По материалам статьи Всеволода Викулина, руководителя внедрения LLM в Поиске Яндекса</em></p>
</div>
    `
  }
];

// Функция для получения локальных статей
export async function getLocalArticles(): Promise<Post[]> {
  return localArticles;
}

// Функция для получения локальной статьи по slug
export async function getLocalArticleBySlug(slug: string): Promise<Post | null> {
  const article = localArticles.find(article => article.slug === slug);
  return article || null;
}

// Функция для добавления новой локальной статьи
export function addLocalArticle(article: Post): void {
  const existingIndex = localArticles.findIndex(a => a.slug === article.slug);
  if (existingIndex >= 0) {
    localArticles[existingIndex] = article;
  } else {
    localArticles.push(article);
  }
}